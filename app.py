import streamlit as st
import pandas as pd
import io
import time
import json
import os
from src.extractor import extract_from_pdf
from src.aggregator import calculate_weekly_summary

st.set_page_config(page_title="å£²ä¸ŠPDFé›†è¨ˆã‚¢ãƒ—ãƒª", layout="wide")

st.title("ğŸ—‚ï¸ å£²ä¸Šå ±å‘ŠPDF è‡ªå‹•é›†è¨ˆãƒ„ãƒ¼ãƒ«")

# --- Manual Data Persistence ---
MANUAL_DATA_FILE = "manual_data.json"

def load_manual_data():
    if os.path.exists(MANUAL_DATA_FILE):
        try:
            with open(MANUAL_DATA_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_manual_data(data):
    with open(MANUAL_DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

if 'manual_data' not in st.session_state:
    st.session_state['manual_data'] = load_manual_data()
# -------------------------------

# --- Authentication ---
AUTH_PASSWORD = st.secrets["AUTH_PASSWORD"]  # ç°¡æ˜“çš„ãªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¾Œã§å¤‰æ›´å¯èƒ½ï¼‰
password = st.sidebar.text_input("èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")

if password != AUTH_PASSWORD:
    st.warning("ğŸ‘ˆ å·¦å´ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.image("https://placehold.co/600x400?text=Please+Login", caption="Login Required")
    st.stop()  # Stop execution if password is wrong
# ----------------------


st.markdown("""
æ—¥æ¬¡ã®å£²ä¸ŠPDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰ã€‚
è‡ªå‹•çš„ã«æ•°å€¤ã‚’èª­ã¿å–ã‚Šã€ãƒ–ãƒ­ãƒƒã‚¯æ¥­ç¨®ã”ã¨ã®é€±æ¬¡ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚
""")

@st.cache_data(ttl="2h")
def process_file_content(file_bytes, filename):
    """
    Cache the expensive OCR/extraction process.
    Pass file content as bytes to ensure proper hashing.
    """
    # Wrap bytes back into a file-like object for pdfplumber
    file_obj = io.BytesIO(file_bytes)
    return extract_from_pdf(file_obj, filename=filename)


uploaded_files = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type="pdf", accept_multiple_files=True)

if uploaded_files:
    st.info(f"{len(uploaded_files)} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...")
    
    extracted_data = [] # Raw extraction from PDFs
    
    progress_bar = st.progress(0)
    
    for i, file in enumerate(uploaded_files):
        # Streamlit file object works with pdfplumber
        # Pass bytes to cached function
        df = process_file_content(file.getvalue(), file.name)
        if df is not None and not df.empty:
            extracted_data.append(df)
        progress_bar.progress((i + 1) / len(uploaded_files))
        
    if extracted_data:
        raw_concatenated = pd.concat(extracted_data, ignore_index=True)
        
        # --- Error Handling & Validation ---
        # 1. Unreadable File Markers
        error_df_ocr = raw_concatenated[raw_concatenated['Zone'].str.contains('ERR:', na=False)].copy()
        
        # 2. Suspicious Data (Sales = 0) - likely misread or empty but valid PDF
        # We assume Sales=0 is impossible for a business day, as per user.
        warnings_df = raw_concatenated[
            (~raw_concatenated['Zone'].str.contains('ERR:', na=False)) & 
            (raw_concatenated['Sales'] == 0) &
            (raw_concatenated['Zone'].str.contains('è»½äº•æ²¢ï¼°ï¼³ï¼° è¨ˆ|ç·åˆè¨ˆ', na=False)) # Only check Total rows for strictness
        ].copy()
        
        # Combine errors
        unique_errors = []
        if not error_df_ocr.empty:
            for _, row in error_df_ocr.iterrows():
                fname = row['Zone'].split(':')[-1]
                unique_errors.append(f"ğŸ“„ **{fname}** (èª­ã¿å–ã‚Šå¤±æ•—: {row['Date']})")
        
        if not warnings_df.empty:
             for _, row in warnings_df.iterrows():
                unique_errors.append(f"âš ï¸ **æ—¥ä»˜: {row['Date']}** (å£²ä¸Š0å†† - èª¤æ¤œçŸ¥ã®å¯èƒ½æ€§ã‚ã‚Š)")

        # Filter out invalid rows from main data
        valid_df = raw_concatenated[
            (~raw_concatenated['Zone'].str.contains('ERR:', na=False)) & 
            (raw_concatenated['Sales'] > 0)
        ]
        
        # Explicit Error Display
        if unique_errors:
            st.error("âš ï¸ ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Šã«å¤±æ•—ã€ã¾ãŸã¯å†…å®¹ã«ä¸å‚™ãŒã‚ã‚Šã¾ã™ã€‚æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
            for err in unique_errors:
                st.write(f"- {err}")
        
        # --- Manual Data Entry Form ---
        with st.expander("âœï¸ æ‰‹å‹•ãƒ‡ãƒ¼ã‚¿å…¥åŠ› (èª­å–å¤±æ•—ãƒ»ä¿®æ­£ç”¨)", expanded=bool(unique_errors)):
            st.caption("èª­ã¿å–ã‚Œãªã‹ã£ãŸã€ã¾ãŸã¯æ•°å€¤ãŒæ­£ã—ããªã„æ—¥ã®ã€Œç·åˆè¨ˆã€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            
            with st.form("manual_entry_form"):
                col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5)
                m_date = col_m1.text_input("æ—¥ä»˜ (ä¾‹: 20260201)", value="")
                m_sales = col_m2.number_input("ç´”å£²ä¸Šé«˜", min_value=0, step=1000)
                m_sales_yoy = col_m3.number_input("å£²ä¸Šå‰å¹´æ¯”(%)", step=0.1)
                m_count = col_m4.number_input("å®¢æ•°", min_value=0, step=10)
                m_count_yoy = col_m5.number_input("å®¢æ•°å‰å¹´æ¯”(%)", step=0.1)
                
                submitted = st.form_submit_button("ãƒ‡ãƒ¼ã‚¿ä¿å­˜/ä¸Šæ›¸ã")
                
                if submitted and m_date:
                    # Save into session state
                    new_entry = {
                        'Date': m_date,
                        'Zone': 'ã€è»½äº•æ²¢ï¼°ï¼³ï¼° è¨ˆã€‘', # Manual entry is always treated as Total
                        'Sales': int(m_sales),
                        'Sales_YoY': float(m_sales_yoy),
                        'Count': int(m_count),
                        'Count_YoY': float(m_count_yoy)
                    }
                    st.session_state['manual_data'][m_date] = new_entry
                    save_manual_data(st.session_state['manual_data'])
                    st.success(f"{m_date} ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                    st.rerun()

        # --- Merge Manual Data ---
        if st.session_state['manual_data']:
            manual_list = list(st.session_state['manual_data'].values())
            manual_df = pd.DataFrame(manual_list)
            
            # Strategy: If Manual Data exists for a Date, drop the Extracted Data for that Date (to prevent dupes/conflicts)
            manual_dates = set(manual_df['Date'].astype(str).str.strip())
            
            # Ensure Date is string matchable
            valid_df['Date'] = valid_df['Date'].astype(str).str.strip()
            
            # Filter out extracted rows that conflict with manual dates
            filtered_valid_df = valid_df[~valid_df['Date'].isin(manual_dates)]
            
            combined_df = pd.concat([filtered_valid_df, manual_df], ignore_index=True)
        else:
            combined_df = valid_df

        # --- Calculate Summary ---
        summary_df = calculate_weekly_summary(combined_df)
        
        st.success("é›†è¨ˆå®Œäº†ï¼")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“Š é€±æ¬¡ã‚µãƒãƒªãƒ¼ï¼ˆæ¥­ç¨®åˆ¥ï¼‰")
            # Formatting for display
            display_df = summary_df.copy()
            
            # Handle potential empty data gracefully
            if not display_df.empty:
                try:
                    display_df['Sales'] = display_df['Sales'].apply(lambda x: f"{int(x):,}")
                    display_df['Count'] = display_df['Count'].apply(lambda x: f"{int(x):,}")
                except: pass
                
                display_df['Sales_YoY'] = display_df['Sales_YoY'].astype(str) + "%"
                display_df['Count_YoY'] = display_df['Count_YoY'].astype(str) + "%"
            
            # Rename columns
            display_df.columns = ['ãƒ–ãƒ­ãƒƒã‚¯/æ¥­ç¨®', 'ç´”å£²ä¸Šé«˜', 'å£²ä¸Šå‰å¹´æ¯”', 'å®¢æ•°', 'å®¢æ•°å‰å¹´æ¯”']
            
            st.dataframe(display_df, use_container_width=True)
            
        with col2:
            st.subheader("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                summary_df.to_excel(writer, sheet_name='é€±æ¬¡ã‚µãƒãƒªãƒ¼', index=False)
                combined_df.to_excel(writer, sheet_name='æ—¥åˆ¥è©³ç´°', index=False)
                
            st.download_button(
                label="Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=buffer.getvalue(),
                file_name=f"å£²ä¸Šé›†è¨ˆ_{time.strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="download_btn"
            )
            
        with st.expander("ğŸ“… æ—¥åˆ¥è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒãƒªãƒ¼ï¼‰", expanded=True):
            st.write("å„æ—¥ã®ç·åˆè¨ˆä¸€è¦§ã§ã™ã€‚")
            if not combined_df.empty:
                # Filter for Total Zone, sort, and Drop Duplicates to be safe
                daily_view = combined_df[combined_df['Zone'].str.contains('è»½äº•æ²¢ï¼°ï¼³ï¼° è¨ˆ|ç·åˆè¨ˆ', na=False)].copy()
                
                # Robust Deduplication
                # Ensure Date is strictly string and clean
                daily_view['Date'] = daily_view['Date'].astype(str).str.strip()
                daily_view = daily_view.sort_values('Date')
                
                # Deduplicate by Date, keeping the last (last is usually better if sorted or manual appends)
                daily_view = daily_view.drop_duplicates(subset=['Date'], keep='last')
                
                # Consistent Formatting
                try:
                    daily_view['Sales'] = daily_view['Sales'].apply(lambda x: f"{int(x):,}")
                    daily_view['Count'] = daily_view['Count'].apply(lambda x: f"{int(x):,}")
                    
                    # Ensure YoY has 1 decimal + % (same as Weekly Summary)
                    # Note: Manual input might be float, extracted might be float. 
                    daily_view['Sales_YoY'] = daily_view['Sales_YoY'].astype(float).round(1).astype(str) + "%"
                    daily_view['Count_YoY'] = daily_view['Count_YoY'].astype(float).round(1).astype(str) + "%"
                except Exception as e:
                    pass

                daily_view = daily_view[['Date', 'Sales', 'Sales_YoY', 'Count', 'Count_YoY']]
                daily_view.columns = ['æ—¥ä»˜', 'ç´”å£²ä¸Šé«˜', 'å£²ä¸Šå‰å¹´æ¯”', 'å®¢æ•°', 'å®¢æ•°å‰å¹´æ¯”']
                
                st.dataframe(daily_view, use_container_width=True)
            else:
                st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            
    else:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚PDFã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
