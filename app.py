import streamlit as st
import pandas as pd
import io
import time
import json
import os
from src.extractor import extract_from_pdf
from src.aggregator import calculate_weekly_summary

st.set_page_config(page_title="å£²ä¸ŠPDFé›†è¨ˆã‚¢ãƒ—ãƒª", layout="wide")

st.title("ğŸ—‚ï¸ å£²ä¸Šå ±å‘ŠPDF è‡ªå‹•é›†è¨ˆãƒ„ãƒ¼ãƒ«")

# --- Manual Data Persistence ---
MANUAL_DATA_FILE = "manual_data.json"

def load_manual_data():
    if os.path.exists(MANUAL_DATA_FILE):
        try:
            with open(MANUAL_DATA_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_manual_data(data):
    with open(MANUAL_DATA_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

if 'manual_data' not in st.session_state:
    st.session_state['manual_data'] = load_manual_data()
# -------------------------------

# --- Authentication ---
AUTH_PASSWORD = st.secrets["AUTH_PASSWORD"]  # ç°¡æ˜“çš„ãªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ï¼ˆå¾Œã§å¤‰æ›´å¯èƒ½ï¼‰
password = st.sidebar.text_input("èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")

if password != AUTH_PASSWORD:
    st.warning("ğŸ‘ˆ å·¦å´ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    st.image("https://placehold.co/600x400?text=Please+Login", caption="Login Required")
    st.stop()  # Stop execution if password is wrong
# ----------------------


st.markdown("""
æ—¥æ¬¡ã®å£²ä¸ŠPDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°å¯ï¼‰ã€‚
è‡ªå‹•çš„ã«æ•°å€¤ã‚’èª­ã¿å–ã‚Šã€ãƒ–ãƒ­ãƒƒã‚¯æ¥­ç¨®ã”ã¨ã®é€±æ¬¡ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚
""")

@st.cache_data(ttl="2h")
def process_file_content(file_bytes, filename):
    """
    Cache the expensive OCR/extraction process.
    Pass file content as bytes to ensure proper hashing.
    """
    # Wrap bytes back into a file-like object for pdfplumber
    file_obj = io.BytesIO(file_bytes)
    return extract_from_pdf(file_obj, filename=filename)


uploaded_files = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type="pdf", accept_multiple_files=True)

if uploaded_files:
    st.info(f"{len(uploaded_files)} å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...")
    
    extracted_data = [] # Raw extraction from PDFs
    
    progress_bar = st.progress(0)
    
    for i, file in enumerate(uploaded_files):
        # Streamlit file object works with pdfplumber
        # Pass bytes to cached function
        df = process_file_content(file.getvalue(), file.name)
        if df is not None and not df.empty:
            extracted_data.append(df)
        progress_bar.progress((i + 1) / len(uploaded_files))
        
    if extracted_data:
        raw_concatenated = pd.concat(extracted_data, ignore_index=True)
        
        # --- Error Handling ---
        # Identify unreadable files
        error_df = raw_concatenated[raw_concatenated['Zone'].str.contains('ERROR_UNREADABLE', na=False)]
        valid_df = raw_concatenated[~raw_concatenated['Zone'].str.contains('ERROR_UNREADABLE', na=False)]
        
        if not error_df.empty:
            st.error("âš ï¸ ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            for _, row in error_df.iterrows():
                fname = row['Zone'].split(':')[-1]
                st.write(f"- ğŸ“„ **{fname}** (æ—¥ä»˜: {row['Date']})")
        
        # --- Manual Data Entry Form ---
        with st.expander("âœï¸ æ‰‹å‹•ãƒ‡ãƒ¼ã‚¿å…¥åŠ› (èª­å–å¤±æ•—æ™‚ç”¨)", expanded=not error_df.empty):
            st.caption("èª­ã¿å–ã‚Œãªã‹ã£ãŸæ—¥ã®ã€Œç·åˆè¨ˆã€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è©³ç´°ã®å…¥åŠ›ã¯ä¸è¦ã§ã™ã€‚")
            
            with st.form("manual_entry_form"):
                col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5)
                m_date = col_m1.text_input("æ—¥ä»˜ (ä¾‹: 20260201)", value="")
                m_sales = col_m2.number_input("ç´”å£²ä¸Šé«˜", min_value=0, step=1000)
                m_sales_yoy = col_m3.number_input("å£²ä¸Šå‰å¹´æ¯”(%)", step=0.1)
                m_count = col_m4.number_input("å®¢æ•°", min_value=0, step=10)
                m_count_yoy = col_m5.number_input("å®¢æ•°å‰å¹´æ¯”(%)", step=0.1)
                
                submitted = st.form_submit_button("ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜")
                
                if submitted and m_date:
                    # Save to session and file
                    new_entry = {
                        'Date': m_date,
                        'Zone': 'ã€è»½äº•æ²¢ï¼°ï¼³ï¼° è¨ˆã€‘', # Treat as Total Zone
                        'Sales': int(m_sales),
                        'Sales_YoY': float(m_sales_yoy),
                        'Count': int(m_count),
                        'Count_YoY': float(m_count_yoy)
                    }
                    st.session_state['manual_data'][m_date] = new_entry
                    save_manual_data(st.session_state['manual_data'])
                    st.success(f"{m_date} ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚é›†è¨ˆã«åæ˜ ã•ã‚Œã¾ã™ã€‚")
                    st.rerun()

        # --- Merge Manual Data ---
        # Convert manual dict to DataFrame
        if st.session_state['manual_data']:
            manual_list = list(st.session_state['manual_data'].values())
            manual_df = pd.DataFrame(manual_list)
            # Combine valid extracted data with manual data
            combined_df = pd.concat([valid_df, manual_df], ignore_index=True)
            # Deduplicate? If extraction succeeded later, prefer extraction? 
            # For now, simple concat. User manages manual data.
        else:
            combined_df = valid_df

        # --- Calculate Summary ---
        summary_df = calculate_weekly_summary(combined_df)
        
        st.success("é›†è¨ˆå®Œäº†ï¼")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“Š é€±æ¬¡ã‚µãƒãƒªãƒ¼ï¼ˆæ¥­ç¨®åˆ¥ï¼‰")
            # Formatting for display
            display_df = summary_df.copy()
            try:
                display_df['Sales'] = display_df['Sales'].apply(lambda x: f"{int(x):,}")
                display_df['Count'] = display_df['Count'].apply(lambda x: f"{int(x):,}")
            except: pass # fallback if non-numeric
            
            display_df['Sales_YoY'] = display_df['Sales_YoY'].astype(str) + "%"
            display_df['Count_YoY'] = display_df['Count_YoY'].astype(str) + "%"
            
            # Rename columns for display
            display_df.columns = ['ãƒ–ãƒ­ãƒƒã‚¯/æ¥­ç¨®', 'ç´”å£²ä¸Šé«˜', 'å£²ä¸Šå‰å¹´æ¯”', 'å®¢æ•°', 'å®¢æ•°å‰å¹´æ¯”']
            
            st.dataframe(display_df, use_container_width=True)
            
        with col2:
            st.subheader("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            
            # Create Excel in memory
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                summary_df.to_excel(writer, sheet_name='é€±æ¬¡ã‚µãƒãƒªãƒ¼', index=False)
                combined_df.to_excel(writer, sheet_name='æ—¥åˆ¥è©³ç´°', index=False)
                
            st.download_button(
                label="Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=buffer.getvalue(),
                file_name=f"å£²ä¸Šé›†è¨ˆ_{time.strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="download_btn"
            )
            
        with st.expander("ğŸ“… æ—¥åˆ¥è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚µãƒãƒªãƒ¼ï¼‰", expanded=True):
            st.write("å„æ—¥ã®ç·åˆè¨ˆä¸€è¦§ã§ã™ã€‚")
            # Filter for Total Zone only to show daily breakdown cleanly
            daily_summary_view = combined_df[combined_df['Zone'].str.contains('è»½äº•æ²¢ï¼°ï¼³ï¼° è¨ˆ|ç·åˆè¨ˆ', na=False)].sort_values('Date')
            
            # Format numbers
            daily_view_fmt = daily_summary_view.copy()
            try:
                daily_view_fmt['Sales'] = daily_view_fmt['Sales'].apply(lambda x: f"{int(x):,}")
                daily_view_fmt['Count'] = daily_view_fmt['Count'].apply(lambda x: f"{int(x):,}")
            except: pass
            
            daily_view_fmt = daily_view_fmt[['Date', 'Sales', 'Sales_YoY', 'Count', 'Count_YoY']]
            daily_view_fmt.columns = ['æ—¥ä»˜', 'ç´”å£²ä¸Šé«˜', 'å£²ä¸Šå‰å¹´æ¯”(%)', 'å®¢æ•°', 'å®¢æ•°å‰å¹´æ¯”(%)']
            
            st.dataframe(daily_view_fmt, use_container_width=True)
            
    else:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚PDFã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
